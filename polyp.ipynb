{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-12-16T08:00:27.498435Z","iopub.execute_input":"2025-12-16T08:00:27.498667Z","iopub.status.idle":"2025-12-16T08:00:44.064853Z","shell.execute_reply.started":"2025-12-16T08:00:27.498646Z","shell.execute_reply":"2025-12-16T08:00:44.064135Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"# Number of class in the data set (3: neoplastic, non neoplastic, background)\nNUM_CLASSES = 3\nBATCH_SIZE = 16\nEPOCHS = 30\nLR = 1e-4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.manual_seed(42)\n\n# Model path\ncheckpoint_path = '/kaggle/working/segformer.pth'","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:02.301469Z","iopub.execute_input":"2025-12-16T08:12:02.301862Z","iopub.status.idle":"2025-12-16T08:12:02.328034Z","shell.execute_reply.started":"2025-12-16T08:12:02.301830Z","shell.execute_reply":"2025-12-16T08:12:02.327275Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"class SegDataset(Dataset):\n    def __init__(self, img_dir, mask_dir):\n        self.imgs = sorted(os.listdir(img_dir))\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.transform = A.Compose([\n            A.Resize(512, 512),\n            A.HorizontalFlip(p=0.5),\n            A.Normalize(),\n            ToTensorV2()\n        ])\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(self.img_dir, self.imgs[idx])).convert(\"RGB\")\n        mask_pil = Image.open(os.path.join(self.mask_dir, self.imgs[idx]))\n        mask_np = np.array(mask_pil)\n\n        # If mask is RGB, convert to single-channel labels\n        if mask_np.ndim == 3 and mask_np.shape[2] == 3:\n            # If channels identical (e.g., saved gray as RGB), take first channel\n            if np.all(mask_np[:, :, 0] == mask_np[:, :, 1]) and np.all(mask_np[:, :, 1] == mask_np[:, :, 2]):\n                mask_np = mask_np[:, :, 0]\n            else:\n                # Colored segmentation map: map each unique RGB color to a class index\n                h, w, _ = mask_np.shape\n                flat = mask_np.reshape(-1, 3)\n                colors, inverse = np.unique(flat, axis=0, return_inverse=True)\n                label_mask = inverse.reshape(h, w).astype(np.uint8)\n                mask_np = label_mask\n\n        # Now mask_np should be 2D (H, W). Handle common encodings like 0/255 for binary masks\n        if mask_np.ndim == 2:\n            if mask_np.max() > (NUM_CLASSES - 1):\n                if NUM_CLASSES == 2:\n                    # Map any non-zero value (e.g., 255) to 1\n                    mask_np = (mask_np > 0).astype(np.uint8)\n                else:\n                    # For multi-class masks with unexpected label values, remap uniques to 0..K-1\n                    uniques = np.unique(mask_np)\n                    mapping = {int(v): i for i, v in enumerate(uniques)}\n                    vec_map = np.vectorize(lambda x: mapping[int(x)])\n                    mask_np = vec_map(mask_np).astype(np.uint8)\n\n        augmented = self.transform(image=np.array(img), mask=mask_np)\n        return augmented[\"image\"], augmented[\"mask\"].long()\n","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:05.144487Z","iopub.execute_input":"2025-12-16T08:12:05.144883Z","iopub.status.idle":"2025-12-16T08:12:05.154781Z","shell.execute_reply.started":"2025-12-16T08:12:05.144858Z","shell.execute_reply":"2025-12-16T08:12:05.153955Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nmasks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:07.925854Z","iopub.execute_input":"2025-12-16T08:12:07.926174Z","iopub.status.idle":"2025-12-16T08:12:07.930310Z","shell.execute_reply.started":"2025-12-16T08:12:07.926151Z","shell.execute_reply":"2025-12-16T08:12:07.929325Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = SegDataset(images_path, masks_path)","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:15.745050Z","iopub.execute_input":"2025-12-16T08:12:15.745989Z","iopub.status.idle":"2025-12-16T08:12:17.803294Z","shell.execute_reply.started":"2025-12-16T08:12:15.745956Z","shell.execute_reply":"2025-12-16T08:12:17.802564Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:17.804576Z","iopub.execute_input":"2025-12-16T08:12:17.804802Z","iopub.status.idle":"2025-12-16T08:12:17.811758Z","shell.execute_reply.started":"2025-12-16T08:12:17.804783Z","shell.execute_reply":"2025-12-16T08:12:17.810897Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d653d91e7b0>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:19.318209Z","iopub.execute_input":"2025-12-16T08:12:19.319018Z","iopub.status.idle":"2025-12-16T08:12:19.337427Z","shell.execute_reply.started":"2025-12-16T08:12:19.318988Z","shell.execute_reply":"2025-12-16T08:12:19.336537Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:21.854571Z","iopub.execute_input":"2025-12-16T08:12:21.854918Z","iopub.status.idle":"2025-12-16T08:12:21.859548Z","shell.execute_reply.started":"2025-12-16T08:12:21.854889Z","shell.execute_reply":"2025-12-16T08:12:21.858674Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from albumentations import (\n    Compose,\n    RandomRotate90,\n    Flip,\n    Transpose,\n    ElasticTransform,\n    GridDistortion,\n    OpticalDistortion,\n    RandomBrightnessContrast,\n    HorizontalFlip,\n    VerticalFlip,\n    RandomGamma,\n    RGBShift,\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:24.335785Z","iopub.execute_input":"2025-12-16T08:12:24.336617Z","iopub.status.idle":"2025-12-16T08:12:24.340412Z","shell.execute_reply.started":"2025-12-16T08:12:24.336586Z","shell.execute_reply":"2025-12-16T08:12:24.339567Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"augmentation = Compose([\n    HorizontalFlip(p=0.5),\n    VerticalFlip(p=0.5),\n    RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n])","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:12:25.831704Z","iopub.execute_input":"2025-12-16T08:12:25.832349Z","iopub.status.idle":"2025-12-16T08:12:25.836906Z","shell.execute_reply.started":"2025-12-16T08:12:25.832319Z","shell.execute_reply":"2025-12-16T08:12:25.835913Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = SegformerForSemanticSegmentation.from_pretrained(\n    \"nvidia/segformer-b0-finetuned-ade-512-512\",\n    num_labels=NUM_CLASSES,\n    ignore_mismatched_sizes=True\n).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:12:27.264189Z","iopub.execute_input":"2025-12-16T08:12:27.264877Z","iopub.status.idle":"2025-12-16T08:12:28.091899Z","shell.execute_reply.started":"2025-12-16T08:12:27.264848Z","shell.execute_reply":"2025-12-16T08:12:28.090952Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f32c9032e8c4a39bb2482ae8abaff65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/15.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d671265fc7549528acdc25e13ee38bb"}},"metadata":{}},{"name":"stderr","text":"Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([3, 256, 1, 1]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class CEDiceLoss(torch.nn.Module):\n    def __init__(self, weights) -> None:\n        super(CEDiceLoss, self).__init__()\n        self.eps: float = 1e-6\n        self.weights: torch.Tensor = weights\n\n    def forward(\n            self,\n            input: torch.Tensor,\n            target: torch.Tensor) -> torch.Tensor:\n        if not torch.is_tensor(input):\n            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        if not len(input.shape) == 4:\n            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n                             .format(input.shape))\n        if not input.shape[-2:] == target.shape[-2:]:\n            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n                             .format(input.shape, input.shape))\n        if not input.device == target.device:\n            raise ValueError(\n                \"input and target must be in the same device. Got: {}\" .format(\n                    input.device, target.device))\n        if not self.weights.shape[1] == input.shape[1]:\n            raise ValueError(\"The number of weights must equal the number of classes\")\n        if not torch.sum(self.weights).item() == 1:\n            raise ValueError(\"The sum of all weights must equal 1\")\n            \n        # cross entropy loss\n        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n        \n        # compute softmax over the classes axis\n        input_soft = F.softmax(input, dim=1)\n\n        # create the labels one hot tensor\n        target_one_hot = one_hot(target, num_classes=input.shape[1],\n                                 device=input.device, dtype=input.dtype)\n\n        # compute the actual dice score\n        dims = (2, 3)\n        intersection = torch.sum(input_soft * target_one_hot, dims)\n        cardinality = torch.sum(input_soft + target_one_hot, dims)\n\n        dice_score = 2. * intersection / (cardinality + self.eps)\n        \n        dice_score = torch.sum(dice_score * self.weights, dim=1)\n        \n        return torch.mean(1. - dice_score) + celoss\n#         return dice_score","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:13:12.340221Z","iopub.execute_input":"2025-12-16T08:13:12.340580Z","iopub.status.idle":"2025-12-16T08:13:12.387823Z","shell.execute_reply.started":"2025-12-16T08:13:12.340550Z","shell.execute_reply":"2025-12-16T08:13:12.386576Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCEDiceLoss\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(CEDiceLoss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"],"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n    for x, y in tqdm(train_loader):\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        out = model(pixel_values=x, labels=y)\n        loss = out.loss\n        print(loss)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch}: Train Loss = {total_loss/len(train_loader):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-16T08:15:05.796296Z","iopub.execute_input":"2025-12-16T08:15:05.797178Z","iopub.status.idle":"2025-12-16T08:15:42.778267Z","shell.execute_reply.started":"2025-12-16T08:15:05.797138Z","shell.execute_reply":"2025-12-16T08:15:42.777152Z"},"trusted":true},"outputs":[{"name":"stderr","text":"  0%|          | 0/57 [00:36<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m----> 5\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(pixel_values\u001b[38;5;241m=\u001b[39mx, labels\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mloss\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# Test function\ndef test(dataloader):\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for i, (data, targets) in enumerate(dataloader):\n            data, targets = data.to(device), targets.to(device)\n            outputs = model(data)\n            _, pred = torch.max(outputs, 1)\n            test_loss += targets.size(0)\n            correct += torch.sum(pred == targets).item()\n    return 100.0 * correct / test_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:59:18.059027Z","iopub.execute_input":"2023-11-17T06:59:18.059289Z","iopub.status.idle":"2023-11-17T06:59:18.074789Z","shell.execute_reply.started":"2023-11-17T06:59:18.059247Z","shell.execute_reply":"2023-11-17T06:59:18.074081Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = Unet(in_channels=3, num_classes = 3)\n\ntry:\n    checkpoint = torch.load(pretrained_path)\n\n    new_state_dict = OrderedDict()\n    for k, v in checkpoint['model'].items():\n        name = k[7:] # remove `module.`\n        new_state_dict[name] = v\n    # load params\n    model.load_state_dict(new_state_dict)\n    model = nn.DataParallel(model)\n    model.to(device)\nexcept:\n    model.apply(weights_init)\n    model = nn.DataParallel(model)\n    model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:59:18.075845Z","iopub.execute_input":"2023-11-17T06:59:18.076102Z","iopub.status.idle":"2023-11-17T06:59:23.010554Z","shell.execute_reply.started":"2023-11-17T06:59:18.07608Z","shell.execute_reply":"2023-11-17T06:59:23.009626Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\nloss_function = CEDiceLoss(weights)\n\n# Define the optimizer (Adam optimizer)\noptimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\ntry: \n    optimizer.load_state_dict(checkpoint['optimizer'])\nexcept:\n    pass\n\n# Learning rate scheduler\nlearing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:59:23.012209Z","iopub.execute_input":"2023-11-17T06:59:23.012585Z","iopub.status.idle":"2023-11-17T06:59:23.021254Z","shell.execute_reply.started":"2023-11-17T06:59:23.012556Z","shell.execute_reply":"2023-11-17T06:59:23.020485Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:59:23.022562Z","iopub.execute_input":"2023-11-17T06:59:23.02287Z","iopub.status.idle":"2023-11-17T06:59:23.238306Z","shell.execute_reply.started":"2023-11-17T06:59:23.022837Z","shell.execute_reply":"2023-11-17T06:59:23.237445Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"90b1c43eb0f9a3084ba785bb7f308f0f948dfb31\",\n)\nwandb.init(\n    project = \"IWillKillAll\"\n)\n# Training loop\ntrain_loss_array = []\ntest_loss_array = []\nlast_loss = 9999999999999\nfor epoch in range(epochs):\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n                                              valid_dataloader, \n                                              learing_rate_scheduler, epoch, display_step)\n    \n    if test_loss_epoch < last_loss:\n        save_model(model, optimizer, checkpoint_path)\n        last_loss = test_loss_epoch\n        \n    learing_rate_scheduler.step()\n    train_loss_array.append(train_loss_epoch)\n    test_loss_array.append(test_loss_epoch)\n    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n#     train_accuracy.append(test(train_loader))\n#     valid_accuracy.append(test(test_loader))\n#     print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n#                                         train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T06:59:23.239644Z","iopub.execute_input":"2023-11-17T06:59:23.240292Z","iopub.status.idle":"2023-11-17T07:16:22.158586Z","shell.execute_reply.started":"2023-11-17T06:59:23.240234Z","shell.execute_reply":"2023-11-17T07:16:22.157134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.160453Z","iopub.execute_input":"2023-11-17T07:16:22.16083Z","iopub.status.idle":"2023-11-17T07:16:22.165938Z","shell.execute_reply.started":"2023-11-17T07:16:22.160794Z","shell.execute_reply":"2023-11-17T07:16:22.165016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.167349Z","iopub.execute_input":"2023-11-17T07:16:22.167861Z","iopub.status.idle":"2023-11-17T07:16:22.187303Z","shell.execute_reply.started":"2023-11-17T07:16:22.167831Z","shell.execute_reply":"2023-11-17T07:16:22.186244Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint = torch.load(pretrained_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.188677Z","iopub.execute_input":"2023-11-17T07:16:22.189017Z","iopub.status.idle":"2023-11-17T07:16:22.218747Z","shell.execute_reply.started":"2023-11-17T07:16:22.188985Z","shell.execute_reply":"2023-11-17T07:16:22.217615Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint = torch.load(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.220069Z","iopub.execute_input":"2023-11-17T07:16:22.220452Z","iopub.status.idle":"2023-11-17T07:16:22.229925Z","shell.execute_reply.started":"2023-11-17T07:16:22.220402Z","shell.execute_reply":"2023-11-17T07:16:22.228906Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for m in self.children():\n#     m.cuda()\n#     x = m(x)\n#     m.cpu()\n#     torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.231089Z","iopub.execute_input":"2023-11-17T07:16:22.231442Z","iopub.status.idle":"2023-11-17T07:16:22.251284Z","shell.execute_reply.started":"2023-11-17T07:16:22.23141Z","shell.execute_reply":"2023-11-17T07:16:22.250402Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot the learning cure","metadata":{}},{"cell_type":"code","source":"# load_model(model, checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.252455Z","iopub.execute_input":"2023-11-17T07:16:22.252711Z","iopub.status.idle":"2023-11-17T07:16:22.264604Z","shell.execute_reply.started":"2023-11-17T07:16:22.252678Z","shell.execute_reply":"2023-11-17T07:16:22.263748Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.rcParams['figure.dpi'] = 90\n# plt.rcParams['figure.figsize'] = (6, 4)\n# epochs_array = range(epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.268144Z","iopub.execute_input":"2023-11-17T07:16:22.268671Z","iopub.status.idle":"2023-11-17T07:16:22.276851Z","shell.execute_reply.started":"2023-11-17T07:16:22.268647Z","shell.execute_reply":"2023-11-17T07:16:22.275777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Plot Training and Test loss\n# plt.plot(epochs_array, train_loss_array, 'g', label='Training loss')\n# # plt.plot(epochs_array, test_loss_array, 'b', label='Test loss')\n# plt.title('Training and Test loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.278397Z","iopub.execute_input":"2023-11-17T07:16:22.278722Z","iopub.status.idle":"2023-11-17T07:16:22.293961Z","shell.execute_reply.started":"2023-11-17T07:16:22.278692Z","shell.execute_reply":"2023-11-17T07:16:22.293103Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Infer**","metadata":{}},{"cell_type":"code","source":"# from torch.jit import load\n# model = UNet()\n# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n\n# checkpoint = torch.load(pretrained_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.295195Z","iopub.execute_input":"2023-11-17T07:16:22.295739Z","iopub.status.idle":"2023-11-17T07:16:22.30745Z","shell.execute_reply.started":"2023-11-17T07:16:22.295709Z","shell.execute_reply":"2023-11-17T07:16:22.306496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# optimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.308722Z","iopub.execute_input":"2023-11-17T07:16:22.309293Z","iopub.status.idle":"2023-11-17T07:16:22.329576Z","shell.execute_reply.started":"2023-11-17T07:16:22.309241Z","shell.execute_reply":"2023-11-17T07:16:22.328633Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from collections import OrderedDict\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.330878Z","iopub.execute_input":"2023-11-17T07:16:22.331394Z","iopub.status.idle":"2023-11-17T07:16:22.341354Z","shell.execute_reply.started":"2023-11-17T07:16:22.331201Z","shell.execute_reply":"2023-11-17T07:16:22.340312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Visualize results**","metadata":{}},{"cell_type":"code","source":"# for i, (data, label) in enumerate(train_dataloader):\n#     img = data\n#     mask = label\n#     break","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.342472Z","iopub.execute_input":"2023-11-17T07:16:22.342986Z","iopub.status.idle":"2023-11-17T07:16:22.354902Z","shell.execute_reply.started":"2023-11-17T07:16:22.342955Z","shell.execute_reply":"2023-11-17T07:16:22.353766Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n# arr[0][0].set_title('Image')\n# arr[0][1].set_title('Segmentation')\n# arr[0][2].set_title('Predict')\n\n# model.eval()\n# with torch.no_grad():\n#     predict = model(img)\n\n# for i in range(4):\n#     arr[i][0].imshow(img[i].permute(1, 2, 0));\n    \n#     arr[i][1].imshow(F.one_hot(mask[i]).float())\n    \n#     arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.356291Z","iopub.execute_input":"2023-11-17T07:16:22.356611Z","iopub.status.idle":"2023-11-17T07:16:22.366673Z","shell.execute_reply.started":"2023-11-17T07:16:22.356586Z","shell.execute_reply":"2023-11-17T07:16:22.365881Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Create submission**","metadata":{}},{"cell_type":"code","source":"# transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n#                      PILToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.367975Z","iopub.execute_input":"2023-11-17T07:16:22.368245Z","iopub.status.idle":"2023-11-17T07:16:22.378016Z","shell.execute_reply.started":"2023-11-17T07:16:22.368222Z","shell.execute_reply":"2023-11-17T07:16:22.377164Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UNetTestDataClass(Dataset):\n    def __init__(self, images_path, transform):\n        super(UNetTestDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        images_list = [images_path+i for i in images_list]\n        \n        self.images_list = images_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.379005Z","iopub.execute_input":"2023-11-17T07:16:22.37944Z","iopub.status.idle":"2023-11-17T07:16:22.391496Z","shell.execute_reply.started":"2023-11-17T07:16:22.379402Z","shell.execute_reply":"2023-11-17T07:16:22.390463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\nunet_test_dataset = UNetTestDataClass(path, transform)\ntest_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.392668Z","iopub.execute_input":"2023-11-17T07:16:22.392993Z","iopub.status.idle":"2023-11-17T07:16:22.430533Z","shell.execute_reply.started":"2023-11-17T07:16:22.392962Z","shell.execute_reply":"2023-11-17T07:16:22.42958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, (data, path, h, w) in enumerate(test_dataloader):\n    img = data\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.431677Z","iopub.execute_input":"2023-11-17T07:16:22.432018Z","iopub.status.idle":"2023-11-17T07:16:22.642651Z","shell.execute_reply.started":"2023-11-17T07:16:22.431988Z","shell.execute_reply":"2023-11-17T07:16:22.641313Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, arr = plt.subplots(5, 2, figsize=(16, 12))\narr[0][0].set_title('Image');\narr[0][1].set_title('Predict');\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(img)\n\nfor i in range(5):\n    arr[i][0].imshow(img[i].permute(1, 2, 0));\n    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:22.643892Z","iopub.execute_input":"2023-11-17T07:16:22.644213Z","iopub.status.idle":"2023-11-17T07:16:24.407437Z","shell.execute_reply.started":"2023-11-17T07:16:22.644187Z","shell.execute_reply":"2023-11-17T07:16:24.406395Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nif not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n    os.mkdir(\"/kaggle/working/predicted_masks\")\nfor _, (img, path, H, W) in enumerate(test_dataloader):\n    a = path\n    b = img\n    h = H\n    w = W\n    \n    with torch.no_grad():\n        predicted_mask = model(b)\n    for i in range(len(a)):\n        image_id = a[i].split('/')[-1].split('.')[0]\n        filename = image_id + \".png\"\n        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:24.408653Z","iopub.execute_input":"2023-11-17T07:16:24.408947Z","iopub.status.idle":"2023-11-17T07:16:40.900046Z","shell.execute_reply.started":"2023-11-17T07:16:24.408921Z","shell.execute_reply":"2023-11-17T07:16:40.898779Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T07:16:40.901648Z","iopub.execute_input":"2023-11-17T07:16:40.902041Z","iopub.status.idle":"2023-11-17T07:16:43.898877Z","shell.execute_reply.started":"2023-11-17T07:16:40.901995Z","shell.execute_reply":"2023-11-17T07:16:43.897848Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}